# 3D_Object_Captioning
3D Vision-Language Agent: From Point Clouds to Natural Language

## ğŸ¯Goal
### ğŸ—‚ï¸Input
* 3D model files (`.ply`, `.obj`, `.pcd`), which will be converted into point cloud.

### ğŸ“Output
* Description of objects in natural languages (captioning)
* Cross-references between text and 3D models.

## âœ¨Features
### ğŸ“¤Upload 3D File
Users upload 3D files via a frontend API.

### ğŸ› ï¸Pre-process Point Cloud
Standardize, sample, and normalize point cloud.

### ğŸ›ï¸Extract 3D Feature
Extract high-dimensional feature vectors using PointNet++ / PointNetXt.

### ğŸ’¬Generate Captions
A LLM pipeline converts 3D features into natural language descriptions.

### ğŸ—ƒï¸Construct Embedding Index
Build a vector database using the 3D features or the generated caption embedding.

### ğŸ”Retrieval API
Enable users to search 3D models by captions, or search captions by 3D models.

### ğŸ–¼ï¸Showcase Page
A page which renders the 3D models (enables 360-degree rotation views), together with the generated captions.

## âš™ï¸Requirements
* Inference time < 3s / model
* Program can be run on a Colab GPU instance.

## ğŸ—ï¸System Design
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Upload   â”‚
â”‚ 3D Model      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing â”‚
â”‚  - Sampling   â”‚
â”‚  - Normalizingâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PointNet++ /  â”‚
â”‚ PointNeXt     â”‚
â”‚ Feature Extractâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Prompting â”‚
â”‚ Caption Gen   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector DB     â”‚
â”‚ (FAISS)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit UI â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸ› ï¸Used Libraries
* Read/Process Point Cloud: `open3d`
* Deep Learning: `torch`, `torchvision`, `torch-geometric`
* 3D models: `torch-point3d`, `torch-points-kernels`
* LLM APIs: `openai`, `google-generativeai`
* Vector Database: `faiss`, `chromadb`
* Front End: `gradio`, `streamlit`

## ğŸ“šRelated Papers
* *PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space* [arXiv](https://arxiv.org/abs/1706.02413)
* *PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies (CVPR 2023)* [arXiv](https://arxiv.org/abs/2206.04670)
* *PaliGemma: A versatile 3B VLM for transfer* [arXiv](https://arxiv.org/abs/2407.07726)

## ğŸ“‚Project Structure
```
.
â”œâ”€â”€ data/                # 3D model examples
â”œâ”€â”€ notebooks/           # Colab notebooks
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess.py    # Pre-process point cloud
â”‚   â”œâ”€â”€ extract_feat.py  # 3D feature extraction
â”‚   â”œâ”€â”€ caption.py       # Caption generation
â”‚   â””â”€â”€ retrieval.py     # Text-3D retrieval
â”œâ”€â”€ app/                 # Streamlit frontend
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ architecture.png     # System design
```